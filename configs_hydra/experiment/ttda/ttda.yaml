# @package _global_

ttda_hook: 
  type: TTDAHook
  turn_on_adapt: true # for test source-only
  adapt_img_vis_freq: ??? # for adapt, can see the proto for learning
  use_pseudo_label: ???
  pseudo_use_ori: true # use freezed source label for pseudo label
  slide_adapt: ???
  high_conf_mask:
    turn_on: ???
    metric: confidence # TODO to implement
    use_history: true
    top_p: 0.3 # only keep top_p pixels, others set to 255
  proto_predict:
    turn_on: ???
    rho: count # for updating prototype, history_proto = (1-rho) * history_proto + rho * proto_this_img
    lambda_: 0.0 # for using prototype, final_proto = lambda_ * history_proto + (1 - lambda_) * proto_this_img. if "count", use count as lambda
    norm_feats: true
    proto_mask_top_p: 0.9 # 
    proto_mask_metric: "entropy" # confidence, entropy, ground_truth, none
    proto_mask_use_history: false # whether top_p threshold is based on all history metric or only this img
  ema:
    turn_on: ???
    rho: 0.1



optim_wrapper:
  paramwise_cfg:
    custom_keys:
      head:
        lr_mult: 1.0
      back:
        lr_mult: 0.0 # does not train backbone
      .norm: # ! since we can not have . in name
        lr_mult: ${norm_lr_mult} # ! how to decide order?
      token_prompt:
        lr_mult: 1.0
      tpt_gates: 
        lr_mult: 10.0
norm_lr_mult: 1.0

custom_hooks:
  - ${ttda_hook} # ! change ttda_hook.xxx so that could be logged in wandb

default_hooks:
  visualization:
    draw: ??? # true
    interval: ??? # draw seg figure
  logger:
    interval: 10

train_cfg:
  val_interval: 100 # not used since this is TTDA

load_from: ??? # ! load from mmseg model


### TPT
model:
  type: EncoderDecoderWrapper
  backbone:
    type: MixVisionTransformerTPT
    tpt_cfg:
      num_tokens: 3
      weight_init_type: normal # zero, normal, kv_normal, q_normal
      mode: llama # llama, vpt # TODO
# model:
#   test_cfg:
#     mode: slide

train: false
test: true
tags: [ttda_debug]
task_name: MMSEG