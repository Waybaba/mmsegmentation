

backbone:
  init_cfg:
    checkpoint: ???
    type: Pretrained
  attn_drop_rate: 0.0
  drop_path_rate: 0.1
  drop_rate: 0.0
  embed_dims: 32
  in_channels: 3
  mlp_ratio: 4
  num_heads: [1, 2, 5, 8]
  num_layers: [2, 2, 2, 2]
  num_stages: 4
  out_indices:
    _args_:
    - [0, 1, 2, 3]
    _target_: builtins.tuple
  patch_sizes: [7, 3, 3, 3]
  qkv_bias: true
  sr_ratios: [8, 4, 2, 1]
  type: MixVisionTransformer
data_preprocessor:
  size: ${crop_size}
  bgr_to_rgb: true
  mean: [123.675, 116.28, 103.53]
  pad_val: 0
  seg_pad_val: 255
  std: [58.395, 57.12, 57.375]
  type: SegDataPreProcessor
decode_head:
  align_corners: false
  channels: 256
  dropout_ratio: 0.1
  in_channels: [32, 64, 160, 256]
  in_index: [0, 1, 2, 3]
  loss_decode:
    loss_weight: 1.0
    type: CrossEntropyLoss
    use_sigmoid: false
  norm_cfg:
    requires_grad: true
    type: SyncBN
  num_classes: 19
  type: SegformerHead
pretrained: null
test_cfg:
  mode: whole # ! would this work?
  crop_size: ${crop_size} # *id001
  stride:
    _args_:
    - ${stride_list_} # 0.75 * crop_size e.g. [768, 768]
    _target_: builtins.tuple
train_cfg: {}
type: EncoderDecoder
